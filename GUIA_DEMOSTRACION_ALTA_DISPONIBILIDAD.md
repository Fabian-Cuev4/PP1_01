# üöÄ GU√çA DE DEMOSTRACI√ìN - ALTA DISPONIBILIDAD SIGLAB

## üìã RESUMEN DE LA INFRAESTRUCTURA

Esta implementaci√≥n demuestra **Alta Disponibilidad** con:
- **1 Nginx Load Balancer** (Puerto 8080) - Punto √∫nico de entrada
- **2 Servidores API** (api_back_1, api_back_2) - Balanceo de carga
- **2 Bases de Datos Compartidas** (MySQL + MongoDB) - Archivador central
- **Dashboard VTS** (Puerto 8084) - Monitoreo visual en tiempo real

## üåê **PUERTOS DE ACCESO**

### **APLICACI√ìN PRINCIPAL (Frontend + Load Balancer)**
```
http://localhost:8080
```
- Punto de entrada √∫nico para todos los usuarios
- Load Balancer autom√°tico entre APIs
- Sticky Sessions activadas

### **DASHBOARD DE MONITOREO VTS**
```
http://localhost:8084/dashboard
```
- M√©tricas en tiempo real
- Tr√°fico en PORCENTAJES (%)
- Estados UP/DOWN con colores

### **SERVIDORES API (Acceso Directo)**
```
API Servidor 1: http://localhost:18001
API Servidor 2: http://localhost:18002
```
- Para pruebas individuales
- Logs de identificaci√≥n
- Conexi√≥n a bases de datos compartidas

### **BASES DE DATOS (Acceso Directo)**
```
MySQL: localhost:13306
MongoDB: localhost:27018
```
- Archivador central compartido
- Persistencia de datos
- Acceso para administraci√≥n

---

## üéØ DIN√ÅMICA DE LA DEMOSTRACI√ìN (PASO A PASO)

### 1. INICIO DEL SISTEMA
```bash
# Levantar toda la infraestructura
docker-compose up --build

# Verificar que todos los contenedores est√©n activos
docker ps
```

**ESPERADO VER:**
- ‚úÖ `mysql_siglab` (Base de datos central)
- ‚úÖ `mongo_siglab` (Base de datos central)  
- ‚úÖ `api_back_1` (Servidor API 1)
- ‚úÖ `api_back_2` (Servidor API 2)
- ‚úÖ `nginx_balancer_siglab` (Load Balancer + Frontend)

### 2. VERIFICACI√ìN DE CONEXIONES
```bash
# Ver logs de los servidores API para confirmar conexi√≥n a bases de datos
docker logs api_back_1
docker logs api_back_2
```

**ESPERADO VER EN LOGS:**
```
Petici√≥n recibida en API Servidor 1 - GET /api/login
Conectado exitosamente al archivador central (MySQL/Mongo)
=== API Servidor 1 LISTO PARA RECIBIR PETICIONES ===
```

### 3. ACCESO A LA APLICACI√ìN
```bash
# Acceder al frontend a trav√©s del Load Balancer
http://localhost:8080
```

**ESPERADO VER:**
- üåê P√°gina de login del SIGLAB
- ‚úÖ El sistema est√° funcionando a trav√©s del Load Balancer

### 4. MONITOREO EN TIEMPO REAL
```bash
# Abrir dashboard de monitoreo
http://localhost:8084/dashboard
```

**ESPERADO VER:**
- üìä M√©tricas de tr√°fico en PORCENTAJES (%)
- üü¢ Estados UP/DOWN con colores visuales
- üìà Distribuci√≥n de carga entre api_back_1 y api_back_2

### 5. PRUEBA DE CARGA Y STICKY SESSIONS
```bash
# En m√∫ltiples pesta√±as del navegador, hacer peticiones simult√°neas
# O usar curl para simular m√∫ltiples usuarios

curl http://localhost:8080/api/maquinas
curl http://localhost:8080/api/maquinas
curl http://localhost:8080/api/maquinas
```

**VERIFICAR EN LOGS:**
```bash
# Ver logs en tiempo real
docker logs -f api_back_1 &
docker logs -f api_back_2 &
```

**ESPERADO VER:**
- üì• Las peticiones se distribuyen entre ambos servidores
- üîÑ Sticky Sessions mantienen al usuario en el mismo servidor

---

## üí• ESCENARIO DE FALLA - DEMOSTRACI√ìN DE ALTA DISPONIBILIDAD

### PASO CR√çTICO: SIMULAR CA√çDA DE SERVIDOR

```bash
# Matar el servidor API 1 para simular una ca√≠da
docker stop api_back_1

# Verificar que el servidor est√° ca√≠do
docker ps
```

### OBSERVAR EL COMPORTAMIENTO

#### 1. EN EL DASHBOARD VTS (http://localhost:8084/dashboard)
**ESPERADO VER INMEDIATAMENTE:**
- üî¥ `api_back_1` cambia a estado **DOWN** (color rojo)
- üü¢ `api_back_2` muestra **100%** del tr√°fico
- üìä Los porcentajes se actualizan en tiempo real

#### 2. EN LA APLICACI√ìN (http://localhost:8080)
**ESPERADO VER:**
- ‚úÖ La aplicaci√≥n sigue funcionando normalmente
- üîÑ Todas las peticiones van autom√°ticamente a `api_back_2`
- üë§ Los usuarios no notan la ca√≠da

#### 3. EN LOS LOGS
```bash
# Ver logs del servidor sobreviviente
docker logs -f api_back_2
```

**ESPERADO VER:**
```
Petici√≥n recibida en API Servidor 2 - GET /api/maquinas
Petici√≥n recibida en API Servidor 2 - POST /api/login
```

### RECUPERACI√ìN AUTOM√ÅTICA

```bash
# Levantar nuevamente el servidor ca√≠do
docker start api_back_1

# Observar el dashboard VTS
# El servidor volver√° a estado UP y comenzar√° a recibir tr√°fico
```

**ESPERADO VER:**
- üü¢ `api_back_1` vuelve a estado **UP** (color verde)
- ‚öñÔ∏è El tr√°fico se redistribuye autom√°ticamente entre ambos servidores
- üîÑ El Load Balancer detecta la recuperaci√≥n autom√°ticamente

---

## üéØ PUNTOS CLAVE PARA LA EXPOSICI√ìN

### 1. ARQUITECTURA DE ALTA DISPONIBILIDAD
- **Un solo punto de entrada** (Nginx en puerto 8080)
- **M√∫ltiples servidores backend** para distribuci√≥n de carga
- **Bases de datos compartidas** como "archivador central"
- **Monitoreo visual** en tiempo real

### 2. RESILIENCIA AUTOM√ÅTICA
- **Detecci√≥n autom√°tica** de ca√≠das de servidores
- **Redirecci√≥n transparente** del tr√°fico
- **Recuperaci√≥n autom√°tica** sin intervenci√≥n manual
- **Experiencia de usuario** ininterrumpida

### 3. MONITOREO VISUAL
- **Dashboard en tiempo real** (puerto 8084)
- **M√©tricas en porcentajes** para f√°cil comprensi√≥n
- **Estados visuales** (verde/rojo) para identificar problemas
- **Datos hist√≥ricos** de rendimiento

### 4. LOGS DE SEGUIMIENTO
- **Identificaci√≥n clara** del servidor que atiende cada petici√≥n
- **Conexiones a bases de datos** documentadas
- **Eventos de inicio/apagado** registrados

---

## üîß COMANDOS √öTILES PARA LA DEMO

```bash
# Ver estado general del sistema
docker-compose ps

# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs de servidores espec√≠ficos
docker logs api_back_1 -f
docker logs api_back_2 -f

# Ver m√©tricas del Load Balancer
curl http://localhost:8084/status | jq

# Probar balanceo de carga
for i in {1..10}; do curl -s http://localhost:8080/api/maquinas | head -c 50; echo ""; done

# Simular estr√©s
ab -n 100 -c 10 http://localhost:8080/api/maquinas

# Acceso directo a APIs (para pruebas)
curl http://localhost:18001/docs
curl http://localhost:18002/docs
```

---

## üèÜ CONCLUSI√ìN

Esta implementaci√≥n demuestra c√≥mo un **solo Nginx** puede:
1. **Servir el frontend** a los usuarios (puerto 8080)
2. **Balancear la carga** entre m√∫ltiples APIs
3. **Monitorear la salud** del sistema en tiempo real (puerto 8084)
4. **Garantizar continuidad** del servicio ante fallos

**Resultado:** Un sistema robusto, escalable y resiliente listo para producci√≥n.
